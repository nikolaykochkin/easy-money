## Spark master specific configuration
##
master:
  ## @param master.configOptions Use a string to set the config options for in the form "-Dx=y"
  ##
  configOptions:
    -Dspark.hadoop.fs.s3a.endpoint=http://minio:9000
    -Dspark.hadoop.fs.s3a.endpoint.region=local
    -Dspark.hadoop.fs.s3a.path.style.access=true
  ## @param master.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for master nodes
  ##
  extraEnvVarsCM: "spark-config-env"
  ## @param master.extraEnvVarsSecret Name of existing Secret containing extra env vars for master nodes
  ##
  extraEnvVarsSecret: "storage-secret"

## Spark worker specific configuration
##
worker:
  ## @param worker.configOptions Set extra options to configure the worker in the form `-Dx=y`
  ##
  configOptions:
    -Dspark.hadoop.fs.s3a.endpoint=http://minio:9000
    -Dspark.hadoop.fs.s3a.endpoint.region=local
    -Dspark.hadoop.fs.s3a.path.style.access=true
  ## @param worker.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for worker nodes
  ##
  extraEnvVarsCM: "spark-config-env"
  ## @param worker.extraEnvVarsSecret Name of existing Secret containing extra env vars for worker nodes
  ##
  extraEnvVarsSecret: "storage-secret"
  ## @param worker.replicaCount Number of spark workers (will be the minimum number when autoscaling is enabled)
  ##
  replicaCount: 1

## Service parameters
##
service:
  ## @param service.type Kubernetes Service type
  ##
  type: LoadBalancer
